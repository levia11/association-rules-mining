{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset re-split\n",
    "Split original dataset into 4 different dataset. \n",
    "Variables (No. of transactions/No. of items/Average transaction width) are controlled as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "GROCERY_STORE_DATA_PATH = \"./dataset/Groceries.csv\"\n",
    "df = pd.read_csv(GROCERY_STORE_DATA_PATH, index_col=0)\n",
    "\n",
    "def avg_width(df):\n",
    "    avg_width=(df.loc[0:,'items'].apply(lambda x: len(x)).sum())/100\n",
    "    return avg_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resplit_dataset(df,init_transaction=0,end_transaction=100):\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset[\"items\"] = df.loc[init_transaction:end_transaction,\"items\"].apply(lambda x: set(x[1:-1].split(\",\")))\n",
    "    dataset.reset_index(inplace=True,drop=True)\n",
    "    dataset.index = dataset.index+1\n",
    "    items = reduce(lambda a, b: a | b, dataset.values)[0]\n",
    "    item_counts = len(items)\n",
    "    avg_wid = avg_width(dataset)\n",
    "    trans_counts = dataset.shape[0]\n",
    "    \n",
    "    return dataset, items, item_counts, avg_wid, trans_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'cling film/bags', 'chicken', 'tropical fruit', 'photo/film', 'berries', 'white wine', 'specialty bar', 'rolls/buns', 'root vegetables', 'rice', 'salt', 'spread cheese', 'sparkling wine', 'ham', 'bottled beer', 'coffee', 'canned vegetables', 'pickled vegetables', 'specialty chocolate', 'detergent', 'meat spreads', 'newspapers', 'packaged fruit/vegetables', 'bottled water', 'misc. beverages', 'red/blush wine', 'seasonal products', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'softener', 'long life bakery product', 'yogurt', 'oil', 'canned fish', 'frozen dessert', 'hygiene articles', 'cat food', 'sliced cheese', 'brandy', 'salty snack', 'shopping bags', 'candles', 'semi-finished bread', 'pastry', 'processed cheese', 'abrasive cleaner', 'grapes', 'whole milk', 'margarine', 'beverages', 'chocolate marshmallow', 'other vegetables', 'butter', 'candy', 'whipped/sour cream', 'pork', 'dessert', 'flour', 'butter milk', 'cereals', 'napkins', 'chewing gum', 'pasta', 'sugar', 'onions', 'hamburger meat', 'curd cheese', 'turkey', 'frozen potato products', 'frankfurter', 'chocolate', 'artif. sweetener', 'spices', 'ice cream', 'bathroom cleaner', 'pip fruit', 'frozen vegetables', 'curd', 'frozen meals', 'waffles', 'hard cheese', 'sausage', 'zwieback', 'dishes', 'canned beer', 'citrus fruit', 'UHT-milk', 'beef', 'specialty fat', 'soda', 'flower (seeds)', 'sweet spreads', 'domestic eggs', 'fruit/vegetable juice'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "4.11\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# dataset 1 (changing transactions counts)\n",
    "\n",
    "dataset1,items1,item_counts1,avg_width1,trans_counts1 = resplit_dataset(df,init_transaction=20,end_transaction=119)\n",
    "\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items1)\n",
    "print(\"items count:\")\n",
    "print(item_counts1)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width1)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'cling film/bags', 'chicken', 'tropical fruit', 'photo/film', 'berries', 'white wine', 'rolls/buns', 'specialty bar', 'root vegetables', 'rice', 'salt', 'spread cheese', 'sparkling wine', 'ham', 'bottled beer', 'canned fruit', 'coffee', 'canned vegetables', 'pickled vegetables', 'specialty chocolate', 'detergent', 'meat spreads', 'newspapers', 'packaged fruit/vegetables', 'bottled water', 'misc. beverages', 'red/blush wine', 'seasonal products', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'softener', 'long life bakery product', 'yogurt', 'fish', 'oil', 'canned fish', 'frozen dessert', 'hygiene articles', 'cat food', 'sliced cheese', 'brandy', 'salty snack', 'shopping bags', 'candles', 'semi-finished bread', 'pastry', 'processed cheese', 'abrasive cleaner', 'grapes', 'whole milk', 'margarine', 'beverages', 'chocolate marshmallow', 'other vegetables', 'butter', 'candy', 'whipped/sour cream', 'pork', 'dessert', 'flour', 'cereals', 'butter milk', 'napkins', 'chewing gum', 'pasta', 'sugar', 'onions', 'hamburger meat', 'curd cheese', 'turkey', 'frozen potato products', 'frankfurter', 'chocolate', 'artif. sweetener', 'liquor (appetizer)', 'spices', 'ice cream', 'bathroom cleaner', 'pip fruit', 'frozen vegetables', 'curd', 'frozen meals', 'waffles', 'hard cheese', 'sausage', 'zwieback', 'Instant food products', 'dishes', 'white bread', 'canned beer', 'male cosmetics', 'citrus fruit', 'UHT-milk', 'beef', 'specialty fat', 'soda', 'flower (seeds)', 'sweet spreads', 'domestic eggs', 'fruit/vegetable juice'}\n",
      "items count:\n",
      "103\n",
      "average width of transactions:\n",
      "5.02\n",
      "transactions counts:\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "#dataset 2\n",
    "\n",
    "dataset2,items2,item_counts2,avg_width2,trans_counts2 = resplit_dataset(df,init_transaction=10,end_transaction=139)\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items2)\n",
    "print(\"items count:\")\n",
    "print(item_counts2)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width2)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'cling film/bags', 'chicken', 'tropical fruit', 'photo/film', 'berries', 'white wine', 'rolls/buns', 'specialty bar', 'root vegetables', 'rice', 'salt', 'spread cheese', 'sparkling wine', 'bottled beer', 'canned fruit', 'coffee', 'canned vegetables', 'pickled vegetables', 'specialty chocolate', 'detergent', 'meat spreads', 'newspapers', 'packaged fruit/vegetables', 'bottled water', 'misc. beverages', 'red/blush wine', 'seasonal products', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'softener', 'long life bakery product', 'yogurt', 'fish', 'oil', 'canned fish', 'frozen dessert', 'hygiene articles', 'cat food', 'sliced cheese', 'brandy', 'salty snack', 'shopping bags', 'semi-finished bread', 'pastry', 'processed cheese', 'abrasive cleaner', 'grapes', 'whole milk', 'margarine', 'beverages', 'chocolate marshmallow', 'other vegetables', 'butter', 'whipped/sour cream', 'pork', 'dessert', 'flour', 'cereals', 'butter milk', 'napkins', 'chewing gum', 'pasta', 'sugar', 'onions', 'hamburger meat', 'curd cheese', 'turkey', 'frozen potato products', 'frankfurter', 'chocolate', 'artif. sweetener', 'liquor (appetizer)', 'spices', 'ice cream', 'bathroom cleaner', 'frozen vegetables', 'frozen meals', 'waffles', 'hard cheese', 'sausage', 'zwieback', 'Instant food products', 'dishes', 'white bread', 'canned beer', 'citrus fruit', 'UHT-milk', 'beef', 'specialty fat', 'soda', 'flower (seeds)', 'sweet spreads', 'domestic eggs', 'fruit/vegetable juice'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "4.83\n",
      "transactions counts:\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "#controlling variable of item counts\n",
    "\n",
    "removed = {'male cosmetics', 'pip fruit', 'curd','ham','candy', 'candles'}\n",
    "for i in dataset2['items']:\n",
    "    for item in removed:\n",
    "        if item in i:\n",
    "            if len(i)>1:\n",
    "                i.remove(item)\n",
    "\n",
    "items2 = reduce(lambda a, b: a | b, dataset2.values)[0]\n",
    "item_counts2 = len(items2)\n",
    "avg_width2 = avg_width(dataset2)\n",
    "trans_counts2 = dataset2.shape[0]\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items2)\n",
    "print(\"items count:\")\n",
    "print(item_counts2)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width2)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'cling film/bags', 'tropical fruit', 'photo/film', 'white wine', 'berries', 'rolls/buns', 'root vegetables', 'specialty bar', 'salt', 'spread cheese', 'bottled beer', 'ham', 'coffee', 'cocoa drinks', 'canned vegetables', 'make up remover', 'pickled vegetables', 'specialty chocolate', 'meat spreads', 'detergent', 'frozen fish', 'mustard', 'soft cheese', 'newspapers', 'packaged fruit/vegetables', 'bottled water', 'misc. beverages', 'red/blush wine', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'long life bakery product', 'yogurt', 'oil', 'canned fish', 'hygiene articles', 'finished products', 'frozen dessert', 'sliced cheese', 'flower soil/fertilizer', 'salty snack', 'shopping bags', 'candles', 'semi-finished bread', 'popcorn', 'pastry', 'grapes', 'whole milk', 'margarine', 'skin care', 'beverages', 'specialty cheese', 'butter', 'other vegetables', 'cake bar', 'candy', 'whipped/sour cream', 'tea', 'pork', 'dessert', 'flour', 'dish cleaner', 'butter milk', 'cereals', 'house keeping products', 'napkins', 'chewing gum', 'pasta', 'dog food', 'sugar', 'cookware', 'pot plants', 'hamburger meat', 'cleaner', 'onions', 'turkey', 'snack products', 'frankfurter', 'chocolate', 'liquor (appetizer)', 'spices', 'ice cream', 'meat', 'pip fruit', 'potato products', 'frozen vegetables', 'curd', 'frozen meals', 'waffles', 'hard cheese', 'sausage', 'zwieback', 'Instant food products', 'prosecco', 'dishes', 'white bread', 'canned beer', 'female sanitary products', 'citrus fruit', 'UHT-milk', 'beef', 'soda', 'flower (seeds)', 'domestic eggs', 'fruit/vegetable juice'}\n",
      "items count:\n",
      "107\n",
      "average width of transactions:\n",
      "4.19\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# dataset 3 (changing items counts)\n",
    "\n",
    "dataset3,items3,item_counts3,avg_width3,trans_counts3 = resplit_dataset(df,init_transaction=150,end_transaction=249)\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items3)\n",
    "print(\"items count:\")\n",
    "print(item_counts3)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width3)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'vinegar', 'chicken', 'tropical fruit', 'berries', 'white wine', 'root vegetables', 'rolls/buns', 'specialty bar', 'rice', 'salt', 'spread cheese', 'sparkling wine', 'bottled beer', 'ham', 'coffee', 'canned vegetables', 'pickled vegetables', 'soups', 'specialty chocolate', 'meat spreads', 'detergent', 'mustard', 'frozen fish', 'soft cheese', 'newspapers', 'bottled water', 'misc. beverages', 'red/blush wine', 'seasonal products', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'toilet cleaner', 'long life bakery product', 'yogurt', 'dental care', 'oil', 'canned fish', 'hygiene articles', 'ready soups', 'frozen dessert', 'finished products', 'rum', 'cat food', 'sliced cheese', 'salty snack', 'shopping bags', 'semi-finished bread', 'mayonnaise', 'pastry', 'processed cheese', 'grapes', 'margarine', 'whole milk', 'sauces', 'skin care', 'beverages', 'chocolate marshmallow', 'other vegetables', 'butter', 'specialty cheese', 'cake bar', 'roll products ', 'candy', 'whipped/sour cream', 'pork', 'dessert', 'organic products', 'flour', 'dish cleaner', 'butter milk', 'cereals', 'napkins', 'chewing gum', 'pasta', 'sugar', 'nuts/prunes', 'onions', 'pot plants', 'curd cheese', 'hamburger meat', 'instant coffee', 'turkey', 'frankfurter', 'chocolate', 'artif. sweetener', 'pet care', 'baby food', 'liquor (appetizer)', 'ice cream', 'meat', 'specialty vegetables', 'pip fruit', 'frozen vegetables', 'curd', 'liquor', 'hard cheese', 'waffles', 'frozen meals', 'sausage', 'kitchen towels', 'zwieback', 'light bulbs', 'dishes', 'cream', 'white bread', 'canned beer', 'citrus fruit', 'UHT-milk', 'beef', 'soda', 'flower (seeds)', 'domestic eggs', 'fruit/vegetable juice'}\n",
      "items count:\n",
      "116\n",
      "average width of transactions:\n",
      "5.87\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# dataset 4 (changing average width)\n",
    "\n",
    "dataset4,items4,item_counts4,avg_width4,trans_counts4 = resplit_dataset(df,init_transaction=1000,end_transaction=1099)\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items4)\n",
    "print(\"items count:\")\n",
    "print(item_counts4)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width4)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'vinegar', 'tropical fruit', 'berries', 'white wine', 'root vegetables', 'rolls/buns', 'specialty bar', 'rice', 'spread cheese', 'sparkling wine', 'ham', 'coffee', 'canned vegetables', 'pickled vegetables', 'soups', 'specialty chocolate', 'frozen fish', 'newspapers', 'bottled water', 'misc. beverages', 'red/blush wine', 'seasonal products', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'toilet cleaner', 'long life bakery product', 'yogurt', 'dental care', 'oil', 'canned fish', 'hygiene articles', 'ready soups', 'frozen dessert', 'rum', 'cat food', 'shopping bags', 'semi-finished bread', 'pastry', 'processed cheese', 'grapes', 'margarine', 'whole milk', 'sauces', 'beverages', 'other vegetables', 'butter', 'specialty cheese', 'cake bar', 'roll products ', 'whipped/sour cream', 'pork', 'dessert', 'organic products', 'flour', 'dish cleaner', 'butter milk', 'cereals', 'napkins', 'chewing gum', 'pasta', 'sugar', 'nuts/prunes', 'pot plants', 'onions', 'curd cheese', 'hamburger meat', 'instant coffee', 'turkey', 'frankfurter', 'chocolate', 'baby food', 'liquor (appetizer)', 'ice cream', 'meat', 'specialty vegetables', 'pip fruit', 'frozen vegetables', 'curd', 'liquor', 'hard cheese', 'waffles', 'frozen meals', 'sausage', 'kitchen towels', 'zwieback', 'light bulbs', 'dishes', 'white bread', 'canned beer', 'citrus fruit', 'UHT-milk', 'beef', 'flower (seeds)', 'domestic eggs'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "4.81\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#controlling variable of item counts\n",
    "\n",
    "removed = {'chicken', 'cream', 'fruit/vegetable juice', 'whipped/sour cream', 'skin care', 'artif. sweetener', 'detergent', \n",
    "           'sliced cheese', 'soft cheese', 'canned vegetables', 'onions', 'shopping bags', 'soda', 'meat spreads', 'salt', \n",
    "           'finished products', 'mustard', 'mayonnaise', 'chocolate marshmallow', 'bottled beer', 'candy','ice cream', 'salty snack',\n",
    "          'pet care'}\n",
    "for i in dataset4['items']:\n",
    "    for item in removed:\n",
    "        if item in i:\n",
    "            if len(i)>1:\n",
    "                i.remove(item)\n",
    "\n",
    "items4 = reduce(lambda a, b: a | b, dataset4.values)[0]\n",
    "item_counts4 = len(items4)\n",
    "avg_width4=avg_width(dataset4)\n",
    "trans_counts4 = dataset4.shape[0]\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items4)\n",
    "print(\"items count:\")\n",
    "print(item_counts4)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width4)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'condensed milk', 'vinegar', 'tropical fruit', 'berries', 'white wine', 'root vegetables', 'rolls/buns', 'specialty bar', 'rice', 'spread cheese', 'sparkling wine', 'ham', 'coffee', 'canned vegetables', 'pickled vegetables', 'soups', 'specialty chocolate', 'frozen fish', 'newspapers', 'bottled water', 'misc. beverages', 'red/blush wine', 'seasonal products', 'brown bread', 'baking powder', 'cream cheese ', 'herbs', 'toilet cleaner', 'long life bakery product', 'yogurt', 'dental care', 'oil', 'canned fish', 'hygiene articles', 'ready soups', 'frozen dessert', 'rum', 'cat food', 'shopping bags', 'semi-finished bread', 'pastry', 'processed cheese', 'grapes', 'margarine', 'whole milk', 'sauces', 'beverages', 'other vegetables', 'butter', 'specialty cheese', 'cake bar', 'roll products ', 'whipped/sour cream', 'pork', 'dessert', 'organic products', 'flour', 'dish cleaner', 'butter milk', 'cereals', 'napkins', 'chewing gum', 'pasta', 'sugar', 'nuts/prunes', 'pot plants', 'onions', 'curd cheese', 'hamburger meat', 'instant coffee', 'turkey', 'frankfurter', 'chocolate', 'baby food', 'liquor (appetizer)', 'ice cream', 'meat', 'specialty vegetables', 'pip fruit', 'frozen vegetables', 'curd', 'liquor', 'hard cheese', 'waffles', 'frozen meals', 'sausage', 'kitchen towels', 'zwieback', 'light bulbs', 'dishes', 'white bread', 'canned beer', 'citrus fruit', 'UHT-milk', 'beef', 'flower (seeds)', 'domestic eggs'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "6.71\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# vary in average width\n",
    "\n",
    "added = {'specialty cheese', 'misc. beverages'}\n",
    "\n",
    "for i in dataset4['items']:\n",
    "    for item in added:\n",
    "        if item not in i:\n",
    "            i.add(item)\n",
    "\n",
    "items4 = reduce(lambda a, b: a | b, dataset4.values)[0]\n",
    "item_counts4 = len(items4)\n",
    "avg_width4=avg_width(dataset4)\n",
    "trans_counts4 = dataset4.shape[0]\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items4)\n",
    "print(\"items count:\")\n",
    "print(item_counts4)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width4)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setnames = [\"dataset1\",\"dataset2\",\"dataset3\",\"dataset4\"]\n",
    "itemcnts = [item_counts1,item_counts2,item_counts3,item_counts4]\n",
    "avgw = [avg_width1,avg_width2,avg_width3,avg_width4]\n",
    "transcnts = [trans_counts1,trans_counts2,trans_counts3,trans_counts4]\n",
    "\n",
    "datasets = {\n",
    "    'name':setnames,\n",
    "    'item counts':itemcnts,\n",
    "    'average width':avgw,\n",
    "    'transactions counts':transcnts\n",
    "}\n",
    "\n",
    "datasets = pd.DataFrame(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  item counts  average width  transactions counts\n",
      "0  dataset1           97           4.11                  100\n",
      "1  dataset2           97           4.83                  130\n",
      "2  dataset3          107           4.19                  100\n",
      "3  dataset4           97           6.71                  100\n"
     ]
    }
   ],
   "source": [
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules Mining Algorithm Comparison (Brute force & Apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import time\n",
    "from itertools import combinations\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def bf_frequent_items(df, items, item_counts, min_sup=0.05, debug=False):\n",
    "    \"\"\"\n",
    "    generate all possible frequent item sets by relative min support\n",
    "    >>> {1: {(('I5',), 2), (('I2',), 7), (('I1',), 6), (('I3',), 6), (('I4',), 2)},\n",
    "         2: {(('I1', 'I2'), 4), (('I1', 'I3'), 4), (('I1', 'I5'), 2), (('I3', 'I2'), 4), (('I4', 'I2'), 2), (('I5', 'I2'), 2)},\n",
    "         3: {(('I1', 'I3', 'I2'), 2), (('I1', 'I5', 'I2'), 2)}\n",
    "         }\n",
    "    :param df: dataframe\n",
    "    :param items:\n",
    "    :param item_counts: num of items\n",
    "    :param min_sup: fractional relative min support\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"Find frequent item sets by Brute Force\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    frequent_sets = {}  # dictionary, key-> k, value-> k item sets\n",
    "    min_threshold = ceil(df.shape[0] * min_sup)\n",
    "\n",
    "    for k in range(1, 1 + item_counts):\n",
    "        k_item_subsets = combinations(items, k)  # all possible k-item sets\n",
    "        time_start = time.time()\n",
    "        # check satisfied k-item sets\n",
    "        filtered_k_subsets = {(\n",
    "            tuple(k_item_subset), (set(k_item_subset) <= df[\"items\"]).sum()) for k_item_subset in k_item_subsets\n",
    "            if\n",
    "            (set(k_item_subset) <= df[\"items\"]).sum() >= min_threshold}\n",
    "        print(f\"Process {k}-item subsets in {time.time() - time_start: .5f} s\")\n",
    "        # if k subsets support can't satisfy, k + 1, ... can't satisfy\n",
    "        if len(filtered_k_subsets) <= 0:\n",
    "            break\n",
    "        frequent_sets[k] = filtered_k_subsets\n",
    "\n",
    "    if debug:\n",
    "        print(\"Final frequent item sets\")\n",
    "        print(\"=\" * 100)\n",
    "        pprint.pprint(frequent_sets)\n",
    "        print(\"=\" * 100)\n",
    "    return frequent_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_frequent_items(df, items, item_counts, min_sup=0.05, debug=False):\n",
    "    \"\"\"\n",
    "    >>>{1: [(('I1',), 6), (('I2',), 7), (('I3',), 6), (('I4',), 2), (('I5',), 2)],\n",
    "        2: [(('I1', 'I2'), 4),(('I1', 'I3'), 4),(('I1', 'I5'), 2),(('I2', 'I3'), 4),(('I2', 'I4'), 2),(('I2', 'I5'), 2)],\n",
    "        3: [(('I1', 'I2', 'I3'), 2), (('I1', 'I2', 'I5'), 2)]\n",
    "        }\n",
    "    generate frequent item sets by Apriori algorithm\n",
    "    :param df:\n",
    "    :param items:\n",
    "    :param item_counts:\n",
    "    :param min_sup:\n",
    "    :param debug: debug mode\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"Find frequent item sets by Apriori algorithm\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    frequent_sets = {}\n",
    "    hash_sets = {}\n",
    "    min_threshold = ceil(df.shape[0] * min_sup)\n",
    "\n",
    "    # initialized by 1 frequent items\n",
    "    # all elements sorted by dictionary order\n",
    "    time_start = time.time()\n",
    "    frequent_k_item_sets = sorted(\n",
    "        ((tuple(item_set), (set(item_set) <= df[\"items\"]).sum()) for item_set in combinations(items, 1)\n",
    "         if (set(item_set) <= df[\"items\"]).sum() >= min_threshold),\n",
    "        key=lambda x: x[0])\n",
    "    print(f\"Process 1-item subsets in {time.time() - time_start: .5f} s\")\n",
    "    hash_k_sets = {item_set for item_set in combinations(items, 1) if\n",
    "                   (set(item_set) <= df[\"items\"]).sum() >= min_threshold}\n",
    "\n",
    "    frequent_sets[1] = frequent_k_item_sets\n",
    "    if debug:\n",
    "        print(\"1-item frequent sets\")\n",
    "        pprint.pprint(frequent_k_item_sets)\n",
    "\n",
    "    hash_sets[1] = hash_k_sets\n",
    "    if debug:\n",
    "        print(\"1-item hash sets\")\n",
    "        pprint.pprint(hash_k_sets)\n",
    "\n",
    "    # perform level-wise generation by join two k - 1 frequent sets and pruning\n",
    "    for k in range(2, 1 + item_counts):\n",
    "        time_start = time.time()\n",
    "        cur_item_sets = []\n",
    "        cur_hash_sets = set()\n",
    "        for i in range(len(frequent_k_item_sets) - 1):\n",
    "            for j in range(i + 1, len(frequent_k_item_sets)):\n",
    "                # joining : find all candidate k item sets\n",
    "                a, b = frequent_k_item_sets[i], frequent_k_item_sets[j]\n",
    "                if a[0][:-1] == b[0][:-1] and a[0][-1] < b[0][-1]:\n",
    "                    candidate_item_set = a[0] + (b[0][-1],)\n",
    "                    # pruning : checking all k - 1 item subsets of candidate\n",
    "                    candidate_subsets = set(\n",
    "                        map(lambda x: tuple(sorted(x)), combinations(set(candidate_item_set), k - 1)))\n",
    "                    if not candidate_subsets - hash_k_sets:\n",
    "                        candidate_sup = (set(candidate_item_set) <= df[\"items\"]).sum()\n",
    "                        if candidate_sup >= min_threshold:\n",
    "                            cur_item_sets.append((candidate_item_set, candidate_sup))\n",
    "                            cur_hash_sets.add(candidate_item_set)\n",
    "        print(f\"Process {k}-item subsets in {time.time() - time_start: .5f} s\")\n",
    "        if len(cur_item_sets) <= 0:\n",
    "            break\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{k}-item frequent item sets\")\n",
    "            print(cur_item_sets)\n",
    "\n",
    "        frequent_sets[k] = cur_item_sets\n",
    "        frequent_k_item_sets = cur_item_sets\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{k}-item hash sets\")\n",
    "            print(cur_hash_sets)\n",
    "\n",
    "        hash_sets[k] = cur_hash_sets\n",
    "        hash_k_sets = cur_hash_sets\n",
    "\n",
    "    if debug:\n",
    "        print(\"Final frequent item sets\")\n",
    "        print(\"=\" * 100)\n",
    "        pprint.pprint(frequent_sets)\n",
    "        print(\"=\" * 100)\n",
    "    return frequent_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "For dataset1 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.03395 s\n",
      "Process 2-item subsets in  0.04700 s\n",
      "Process 3-item subsets in  0.00098 s\n",
      "For dataset2 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01821 s\n",
      "Process 2-item subsets in  0.03243 s\n",
      "Process 3-item subsets in  0.01004 s\n",
      "For dataset3 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01667 s\n",
      "Process 2-item subsets in  0.03929 s\n",
      "Process 3-item subsets in  0.00000 s\n",
      "For dataset4 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.02355 s\n",
      "Process 2-item subsets in  0.09944 s\n",
      "Process 3-item subsets in  0.02453 s\n",
      "Process 4-item subsets in  0.00000 s\n",
      "Process 5-item subsets in  0.01004 s\n",
      "Process 6-item subsets in  0.00000 s\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "For dataset1 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.02108 s\n",
      "Process 2-item subsets in  0.59839 s\n",
      "Process 3-item subsets in  18.04996 s\n",
      "For dataset2 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01000 s\n",
      "Process 2-item subsets in  0.58703 s\n",
      "Process 3-item subsets in  18.51306 s\n",
      "For dataset3 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01000 s\n",
      "Process 2-item subsets in  0.69956 s\n",
      "Process 3-item subsets in  24.32334 s\n",
      "For dataset4 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.02003 s\n",
      "Process 2-item subsets in  0.59097 s\n",
      "Process 3-item subsets in  18.27607 s\n",
      "Process 4-item subsets in  423.79435 s\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "algos = {\n",
    "    \"Apriori\": apriori_frequent_items,  # apriori\n",
    "     \"Brute Force\": bf_frequent_items,  # brute force\n",
    "}\n",
    "\n",
    "try:\n",
    "    for algo in algos.keys():\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(1,5):\n",
    "            print(\"For dataset\"+str(i)+\" : \")\n",
    "            d = vars()[datasets.loc[i-1,'name']]\n",
    "            items = vars()[(\"items\"+str(i))]\n",
    "            item_counts = vars()[(\"item_counts\"+str(i))]\n",
    "            alg_freq_item_sets = algos[algo](d, items, item_counts, min_sup=0.05, debug=False)\n",
    "        print(\"=\" * 100)\n",
    "except KeyboardInterrupt:\n",
    "    print ('Stopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
