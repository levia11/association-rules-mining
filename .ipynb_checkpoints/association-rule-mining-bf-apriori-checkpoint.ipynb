{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset re-split\n",
    "Split original dataset into 4 different dataset. \n",
    "Variables (No. of transactions/No. of items/Average transaction width) are controlled as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "GROCERY_STORE_DATA_PATH = \"./dataset/Groceries.csv\"\n",
    "df = pd.read_csv(GROCERY_STORE_DATA_PATH, index_col=0)\n",
    "\n",
    "def avg_width(df):\n",
    "    avg_width=(df.loc[0:,'items'].apply(lambda x: len(x)).sum())/100\n",
    "    return avg_width\n",
    "\n",
    "def max_width(df):\n",
    "    return df.loc[0:,'items'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resplit_dataset(df,init_transaction=0,end_transaction=100):\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset[\"items\"] = df.loc[init_transaction:end_transaction,\"items\"].apply(lambda x: set(x[1:-1].split(\",\")))\n",
    "    dataset.reset_index(inplace=True,drop=True)\n",
    "    dataset.index = dataset.index+1\n",
    "    items = reduce(lambda a, b: a | b, dataset.values)[0]\n",
    "    item_counts = len(items)\n",
    "    avg_wid = avg_width(dataset)\n",
    "    trans_counts = dataset.shape[0]\n",
    "    \n",
    "    return dataset, items, item_counts, avg_wid, trans_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'seasonal products', 'candy', 'sliced cheese', 'packaged fruit/vegetables', 'bottled water', 'pastry', 'ham', 'chewing gum', 'herbs', 'berries', 'abrasive cleaner', 'soda', 'frankfurter', 'softener', 'bathroom cleaner', 'hard cheese', 'detergent', 'cereals', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'condensed milk', 'long life bakery product', 'curd cheese', 'whipped/sour cream', 'grapes', 'rolls/buns', 'white wine', 'canned fish', 'brandy', 'tropical fruit', 'flour', 'chocolate', 'butter milk', 'pork', 'onions', 'frozen dessert', 'whole milk', 'salt', 'processed cheese', 'semi-finished bread', 'shopping bags', 'beef', 'cream cheese ', 'chicken', 'domestic eggs', 'salty snack', 'meat spreads', 'newspapers', 'sausage', 'turkey', 'baking powder', 'oil', 'specialty chocolate', 'hamburger meat', 'red/blush wine', 'canned beer', 'misc. beverages', 'specialty fat', 'sugar', 'pip fruit', 'pasta', 'cling film/bags', 'fruit/vegetable juice', 'coffee', 'cat food', 'curd', 'rice', 'specialty bar', 'brown bread', 'dessert', 'sweet spreads', 'beverages', 'spices', 'canned vegetables', 'UHT-milk', 'chocolate marshmallow', 'other vegetables', 'candles', 'butter', 'pickled vegetables', 'bottled beer', 'artif. sweetener', 'hygiene articles', 'photo/film', 'sparkling wine', 'frozen meals', 'napkins', 'yogurt', 'dishes', 'margarine', 'frozen vegetables', 'frozen potato products', 'spread cheese', 'ice cream', 'flower (seeds)'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "4.11\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# dataset 1 (changing transactions counts)\n",
    "\n",
    "dataset1,items1,item_counts1,avg_width1,trans_counts1 = resplit_dataset(df,init_transaction=20,end_transaction=119)\n",
    "\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items1)\n",
    "print(\"items count:\")\n",
    "print(item_counts1)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width1)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'seasonal products', 'candy', 'sliced cheese', 'packaged fruit/vegetables', 'bottled water', 'pastry', 'ham', 'chewing gum', 'herbs', 'liquor (appetizer)', 'berries', 'abrasive cleaner', 'soda', 'frankfurter', 'softener', 'fish', 'bathroom cleaner', 'hard cheese', 'cereals', 'detergent', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'condensed milk', 'long life bakery product', 'curd cheese', 'whipped/sour cream', 'grapes', 'rolls/buns', 'Instant food products', 'white wine', 'canned fish', 'canned fruit', 'brandy', 'tropical fruit', 'chocolate', 'flour', 'butter milk', 'pork', 'onions', 'frozen dessert', 'whole milk', 'salt', 'processed cheese', 'semi-finished bread', 'shopping bags', 'beef', 'chicken', 'cream cheese ', 'domestic eggs', 'salty snack', 'meat spreads', 'newspapers', 'sausage', 'turkey', 'baking powder', 'oil', 'specialty chocolate', 'hamburger meat', 'red/blush wine', 'canned beer', 'misc. beverages', 'specialty fat', 'sugar', 'pip fruit', 'pasta', 'cling film/bags', 'fruit/vegetable juice', 'coffee', 'cat food', 'curd', 'rice', 'specialty bar', 'brown bread', 'dessert', 'sweet spreads', 'beverages', 'spices', 'canned vegetables', 'UHT-milk', 'chocolate marshmallow', 'other vegetables', 'flower (seeds)', 'candles', 'butter', 'pickled vegetables', 'bottled beer', 'artif. sweetener', 'hygiene articles', 'photo/film', 'sparkling wine', 'dishes', 'napkins', 'yogurt', 'frozen meals', 'margarine', 'male cosmetics', 'frozen vegetables', 'frozen potato products', 'spread cheese', 'ice cream', 'white bread'}\n",
      "items count:\n",
      "103\n",
      "average width of transactions:\n",
      "5.02\n",
      "transactions counts:\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "#dataset 2\n",
    "\n",
    "dataset2,items2,item_counts2,avg_width2,trans_counts2 = resplit_dataset(df,init_transaction=10,end_transaction=139)\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items2)\n",
    "print(\"items count:\")\n",
    "print(item_counts2)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width2)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'seasonal products', 'sliced cheese', 'packaged fruit/vegetables', 'bottled water', 'pastry', 'chewing gum', 'herbs', 'liquor (appetizer)', 'berries', 'abrasive cleaner', 'soda', 'frankfurter', 'softener', 'fish', 'bathroom cleaner', 'hard cheese', 'cereals', 'detergent', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'condensed milk', 'long life bakery product', 'curd cheese', 'whipped/sour cream', 'grapes', 'rolls/buns', 'Instant food products', 'white wine', 'canned fish', 'canned fruit', 'brandy', 'tropical fruit', 'chocolate', 'flour', 'butter milk', 'pork', 'onions', 'frozen dessert', 'whole milk', 'salt', 'processed cheese', 'semi-finished bread', 'shopping bags', 'beef', 'chicken', 'cream cheese ', 'domestic eggs', 'salty snack', 'meat spreads', 'newspapers', 'sausage', 'turkey', 'baking powder', 'oil', 'specialty chocolate', 'hamburger meat', 'red/blush wine', 'canned beer', 'misc. beverages', 'specialty fat', 'sugar', 'pasta', 'cling film/bags', 'fruit/vegetable juice', 'coffee', 'cat food', 'rice', 'specialty bar', 'brown bread', 'dessert', 'sweet spreads', 'beverages', 'spices', 'canned vegetables', 'UHT-milk', 'chocolate marshmallow', 'other vegetables', 'flower (seeds)', 'butter', 'pickled vegetables', 'bottled beer', 'artif. sweetener', 'hygiene articles', 'photo/film', 'sparkling wine', 'dishes', 'napkins', 'yogurt', 'frozen meals', 'margarine', 'frozen vegetables', 'frozen potato products', 'spread cheese', 'ice cream', 'white bread'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "4.83\n",
      "transactions counts:\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "#controlling variable of item counts\n",
    "\n",
    "removed = {'male cosmetics', 'pip fruit', 'curd','ham','candy', 'candles'}\n",
    "for i in dataset2['items']:\n",
    "    for item in removed:\n",
    "        if item in i:\n",
    "            if len(i)>1:\n",
    "                i.remove(item)\n",
    "\n",
    "items2 = reduce(lambda a, b: a | b, dataset2.values)[0]\n",
    "item_counts2 = len(items2)\n",
    "avg_width2 = avg_width(dataset2)\n",
    "trans_counts2 = dataset2.shape[0]\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items2)\n",
    "print(\"items count:\")\n",
    "print(item_counts2)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width2)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'candy', 'sliced cheese', 'cake bar', 'bottled water', 'packaged fruit/vegetables', 'pastry', 'ham', 'dish cleaner', 'cleaner', 'herbs', 'chewing gum', 'liquor (appetizer)', 'cookware', 'berries', 'soda', 'frankfurter', 'soft cheese', 'hard cheese', 'cereals', 'detergent', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'condensed milk', 'long life bakery product', 'potato products', 'whipped/sour cream', 'grapes', 'rolls/buns', 'Instant food products', 'prosecco', 'white wine', 'canned fish', 'frozen fish', 'tropical fruit', 'chocolate', 'flour', 'pork', 'butter milk', 'onions', 'skin care', 'salt', 'whole milk', 'frozen dessert', 'semi-finished bread', 'shopping bags', 'dog food', 'pot plants', 'beef', 'cream cheese ', 'domestic eggs', 'salty snack', 'meat spreads', 'mustard', 'sausage', 'newspapers', 'female sanitary products', 'turkey', 'baking powder', 'specialty chocolate', 'oil', 'tea', 'hamburger meat', 'red/blush wine', 'canned beer', 'snack products', 'misc. beverages', 'sugar', 'pip fruit', 'house keeping products', 'cling film/bags', 'pasta', 'popcorn', 'fruit/vegetable juice', 'coffee', 'curd', 'brown bread', 'specialty bar', 'dessert', 'finished products', 'beverages', 'spices', 'canned vegetables', 'UHT-milk', 'specialty cheese', 'flower soil/fertilizer', 'other vegetables', 'candles', 'cocoa drinks', 'meat', 'flower (seeds)', 'butter', 'pickled vegetables', 'bottled beer', 'hygiene articles', 'photo/film', 'frozen meals', 'dishes', 'napkins', 'yogurt', 'margarine', 'make up remover', 'frozen vegetables', 'spread cheese', 'ice cream', 'white bread'}\n",
      "items count:\n",
      "107\n",
      "average width of transactions:\n",
      "4.19\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# dataset 3 (changing items counts)\n",
    "\n",
    "dataset3,items3,item_counts3,avg_width3,trans_counts3 = resplit_dataset(df,init_transaction=150,end_transaction=249)\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items3)\n",
    "print(\"items count:\")\n",
    "print(item_counts3)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width3)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'seasonal products', 'roll products ', 'sliced cheese', 'candy', 'cake bar', 'bottled water', 'pastry', 'ham', 'dish cleaner', 'herbs', 'chewing gum', 'skin care', 'liquor (appetizer)', 'berries', 'toilet cleaner', 'soda', 'frankfurter', 'soft cheese', 'hard cheese', 'cereals', 'condensed milk', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'detergent', 'long life bakery product', 'curd cheese', 'whipped/sour cream', 'grapes', 'rolls/buns', 'white wine', 'canned fish', 'cream', 'mayonnaise', 'nuts/prunes', 'instant coffee', 'frozen fish', 'vinegar', 'tropical fruit', 'flour', 'pork', 'butter milk', 'onions', 'dental care', 'ready soups', 'chocolate', 'white bread', 'whole milk', 'salt', 'semi-finished bread', 'processed cheese', 'frozen dessert', 'light bulbs', 'shopping bags', 'soups', 'pot plants', 'beef', 'cream cheese ', 'chicken', 'domestic eggs', 'salty snack', 'meat spreads', 'mustard', 'newspapers', 'sausage', 'pet care', 'turkey', 'baking powder', 'specialty chocolate', 'oil', 'hamburger meat', 'liquor', 'red/blush wine', 'canned beer', 'misc. beverages', 'sugar', 'pip fruit', 'specialty vegetables', 'fruit/vegetable juice', 'coffee', 'cat food', 'curd', 'rice', 'specialty bar', 'organic products', 'brown bread', 'dessert', 'kitchen towels', 'finished products', 'beverages', 'canned vegetables', 'UHT-milk', 'chocolate marshmallow', 'specialty cheese', 'other vegetables', 'meat', 'flower (seeds)', 'butter', 'pickled vegetables', 'sauces', 'bottled beer', 'artif. sweetener', 'baby food', 'hygiene articles', 'rum', 'sparkling wine', 'dishes', 'napkins', 'yogurt', 'frozen meals', 'margarine', 'frozen vegetables', 'spread cheese', 'ice cream', 'pasta'}\n",
      "items count:\n",
      "116\n",
      "average width of transactions:\n",
      "5.87\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# dataset 4 (changing average width)\n",
    "\n",
    "dataset4,items4,item_counts4,avg_width4,trans_counts4 = resplit_dataset(df,init_transaction=1000,end_transaction=1099)\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items4)\n",
    "print(\"items count:\")\n",
    "print(item_counts4)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width4)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'seasonal products', 'roll products ', 'cake bar', 'bottled water', 'pastry', 'ham', 'dish cleaner', 'herbs', 'chewing gum', 'liquor (appetizer)', 'berries', 'toilet cleaner', 'frankfurter', 'hard cheese', 'cereals', 'condensed milk', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'long life bakery product', 'curd cheese', 'whipped/sour cream', 'grapes', 'rolls/buns', 'white wine', 'canned fish', 'nuts/prunes', 'instant coffee', 'frozen fish', 'vinegar', 'tropical fruit', 'flour', 'pork', 'butter milk', 'dental care', 'ready soups', 'onions', 'chocolate', 'frozen dessert', 'whole milk', 'light bulbs', 'semi-finished bread', 'processed cheese', 'soups', 'shopping bags', 'pot plants', 'beef', 'cream cheese ', 'domestic eggs', 'newspapers', 'sausage', 'turkey', 'baking powder', 'specialty chocolate', 'oil', 'hamburger meat', 'liquor', 'red/blush wine', 'canned beer', 'misc. beverages', 'sugar', 'pip fruit', 'pasta', 'specialty vegetables', 'coffee', 'cat food', 'curd', 'rice', 'specialty bar', 'organic products', 'brown bread', 'dessert', 'kitchen towels', 'beverages', 'canned vegetables', 'UHT-milk', 'specialty cheese', 'other vegetables', 'meat', 'flower (seeds)', 'butter', 'pickled vegetables', 'sauces', 'baby food', 'hygiene articles', 'rum', 'sparkling wine', 'dishes', 'napkins', 'yogurt', 'frozen meals', 'margarine', 'frozen vegetables', 'spread cheese', 'ice cream', 'white bread'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "4.81\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#controlling variable of item counts\n",
    "\n",
    "removed = {'chicken', 'cream', 'fruit/vegetable juice', 'whipped/sour cream', 'skin care', 'artif. sweetener', 'detergent', \n",
    "           'sliced cheese', 'soft cheese', 'canned vegetables', 'onions', 'shopping bags', 'soda', 'meat spreads', 'salt', \n",
    "           'finished products', 'mustard', 'mayonnaise', 'chocolate marshmallow', 'bottled beer', 'candy','ice cream', 'salty snack',\n",
    "          'pet care'}\n",
    "for i in dataset4['items']:\n",
    "    for item in removed:\n",
    "        if item in i:\n",
    "            if len(i)>1:\n",
    "                i.remove(item)\n",
    "\n",
    "items4 = reduce(lambda a, b: a | b, dataset4.values)[0]\n",
    "item_counts4 = len(items4)\n",
    "avg_width4=avg_width(dataset4)\n",
    "trans_counts4 = dataset4.shape[0]\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items4)\n",
    "print(\"items count:\")\n",
    "print(item_counts4)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width4)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items set:\n",
      "{'seasonal products', 'roll products ', 'cake bar', 'bottled water', 'pastry', 'ham', 'dish cleaner', 'herbs', 'chewing gum', 'liquor (appetizer)', 'berries', 'toilet cleaner', 'frankfurter', 'hard cheese', 'cereals', 'condensed milk', 'root vegetables', 'zwieback', 'waffles', 'citrus fruit', 'long life bakery product', 'curd cheese', 'whipped/sour cream', 'grapes', 'rolls/buns', 'white wine', 'canned fish', 'nuts/prunes', 'instant coffee', 'frozen fish', 'vinegar', 'tropical fruit', 'flour', 'pork', 'butter milk', 'dental care', 'ready soups', 'onions', 'chocolate', 'white bread', 'whole milk', 'frozen dessert', 'semi-finished bread', 'processed cheese', 'light bulbs', 'soups', 'shopping bags', 'pot plants', 'beef', 'cream cheese ', 'domestic eggs', 'newspapers', 'sausage', 'turkey', 'baking powder', 'specialty chocolate', 'oil', 'hamburger meat', 'liquor', 'red/blush wine', 'misc. beverages', 'canned beer', 'sugar', 'pip fruit', 'specialty vegetables', 'coffee', 'cat food', 'curd', 'rice', 'specialty bar', 'organic products', 'brown bread', 'dessert', 'kitchen towels', 'beverages', 'canned vegetables', 'UHT-milk', 'specialty cheese', 'other vegetables', 'meat', 'flower (seeds)', 'butter', 'pickled vegetables', 'sauces', 'baby food', 'hygiene articles', 'rum', 'sparkling wine', 'dishes', 'napkins', 'yogurt', 'frozen meals', 'margarine', 'frozen vegetables', 'spread cheese', 'ice cream', 'pasta'}\n",
      "items count:\n",
      "97\n",
      "average width of transactions:\n",
      "6.71\n",
      "transactions counts:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# vary in average width\n",
    "\n",
    "added = {'specialty cheese', 'misc. beverages'}\n",
    "\n",
    "for i in dataset4['items']:\n",
    "    for item in added:\n",
    "        if item not in i:\n",
    "            i.add(item)\n",
    "\n",
    "items4 = reduce(lambda a, b: a | b, dataset4.values)[0]\n",
    "item_counts4 = len(items4)\n",
    "avg_width4=avg_width(dataset4)\n",
    "trans_counts4 = dataset4.shape[0]\n",
    "\n",
    "print(\"items set:\")\n",
    "print(items4)\n",
    "print(\"items count:\")\n",
    "print(item_counts4)\n",
    "print(\"average width of transactions:\")\n",
    "print(avg_width4)\n",
    "print(\"transactions counts:\")\n",
    "print(trans_counts4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setnames = [\"dataset1\",\"dataset2\",\"dataset3\",\"dataset4\"]\n",
    "itemcnts = [item_counts1,item_counts2,item_counts3,item_counts4]\n",
    "avgw = [avg_width1,avg_width2,avg_width3,avg_width4]\n",
    "transcnts = [trans_counts1,trans_counts2,trans_counts3,trans_counts4]\n",
    "maxw = [max_width(dataset1),max_width(dataset2),max_width(dataset3),max_width(dataset4)]\n",
    "\n",
    "datasets = {\n",
    "    'name':setnames,\n",
    "    'item counts':itemcnts,\n",
    "    'average width':avgw,\n",
    "    'max width': maxw,\n",
    "    'transactions counts':transcnts,\n",
    "}\n",
    "\n",
    "datasets = pd.DataFrame(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  item counts  average width  max width  transactions counts\n",
      "0  dataset1           97           4.11         13                  100\n",
      "1  dataset2           97           4.83         14                  130\n",
      "2  dataset3          107           4.19         23                  100\n",
      "3  dataset4           97           6.71         22                  100\n"
     ]
    }
   ],
   "source": [
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules Mining Algorithm Comparison (Brute force & Apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import time\n",
    "from itertools import combinations\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def bf_frequent_items(df, items, item_counts, min_sup=0.05, debug=False):\n",
    "    \"\"\"\n",
    "    generate all possible frequent item sets by relative min support\n",
    "    >>> {1: {(('I5',), 2), (('I2',), 7), (('I1',), 6), (('I3',), 6), (('I4',), 2)},\n",
    "         2: {(('I1', 'I2'), 4), (('I1', 'I3'), 4), (('I1', 'I5'), 2), (('I3', 'I2'), 4), (('I4', 'I2'), 2), (('I5', 'I2'), 2)},\n",
    "         3: {(('I1', 'I3', 'I2'), 2), (('I1', 'I5', 'I2'), 2)}\n",
    "         }\n",
    "    :param df: dataframe\n",
    "    :param items:\n",
    "    :param item_counts: num of items\n",
    "    :param min_sup: fractional relative min support\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"Find frequent item sets by Brute Force\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    frequent_sets = {}  # dictionary, key-> k, value-> k item sets\n",
    "    min_threshold = ceil(df.shape[0] * min_sup)\n",
    "\n",
    "    for k in range(1, 1 + item_counts):\n",
    "        k_item_subsets = combinations(items, k)  # all possible k-item sets\n",
    "        time_start = time.time()\n",
    "        # check satisfied k-item sets\n",
    "        filtered_k_subsets = {(\n",
    "            tuple(k_item_subset), (set(k_item_subset) <= df[\"items\"]).sum()) for k_item_subset in k_item_subsets\n",
    "            if\n",
    "            (set(k_item_subset) <= df[\"items\"]).sum() >= min_threshold}\n",
    "        print(f\"Process {k}-item subsets in {time.time() - time_start: .5f} s\")\n",
    "        # if k subsets support can't satisfy, k + 1, ... can't satisfy\n",
    "        if len(filtered_k_subsets) <= 0:\n",
    "            break\n",
    "        frequent_sets[k] = filtered_k_subsets\n",
    "\n",
    "    if debug:\n",
    "        print(\"Final frequent item sets\")\n",
    "        print(\"=\" * 100)\n",
    "        pprint.pprint(frequent_sets)\n",
    "        print(\"=\" * 100)\n",
    "    return frequent_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_frequent_items(df, items, item_counts, min_sup=0.05, debug=False):\n",
    "    \"\"\"\n",
    "    >>>{1: [(('I1',), 6), (('I2',), 7), (('I3',), 6), (('I4',), 2), (('I5',), 2)],\n",
    "        2: [(('I1', 'I2'), 4),(('I1', 'I3'), 4),(('I1', 'I5'), 2),(('I2', 'I3'), 4),(('I2', 'I4'), 2),(('I2', 'I5'), 2)],\n",
    "        3: [(('I1', 'I2', 'I3'), 2), (('I1', 'I2', 'I5'), 2)]\n",
    "        }\n",
    "    generate frequent item sets by Apriori algorithm\n",
    "    :param df:\n",
    "    :param items:\n",
    "    :param item_counts:\n",
    "    :param min_sup:\n",
    "    :param debug: debug mode\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"Find frequent item sets by Apriori algorithm\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    frequent_sets = {}\n",
    "    hash_sets = {}\n",
    "    min_threshold = ceil(df.shape[0] * min_sup)\n",
    "\n",
    "    # initialized by 1 frequent items\n",
    "    # all elements sorted by dictionary order\n",
    "    time_start = time.time()\n",
    "    frequent_k_item_sets = sorted(\n",
    "        ((tuple(item_set), (set(item_set) <= df[\"items\"]).sum()) for item_set in combinations(items, 1)\n",
    "         if (set(item_set) <= df[\"items\"]).sum() >= min_threshold),\n",
    "        key=lambda x: x[0])\n",
    "    print(f\"Process 1-item subsets in {time.time() - time_start: .5f} s\")\n",
    "    hash_k_sets = {item_set for item_set in combinations(items, 1) if\n",
    "                   (set(item_set) <= df[\"items\"]).sum() >= min_threshold}\n",
    "\n",
    "    frequent_sets[1] = frequent_k_item_sets\n",
    "    if debug:\n",
    "        print(\"1-item frequent sets\")\n",
    "        pprint.pprint(frequent_k_item_sets)\n",
    "\n",
    "    hash_sets[1] = hash_k_sets\n",
    "    if debug:\n",
    "        print(\"1-item hash sets\")\n",
    "        pprint.pprint(hash_k_sets)\n",
    "\n",
    "    # perform level-wise generation by join two k - 1 frequent sets and pruning\n",
    "    for k in range(2, 1 + item_counts):\n",
    "        time_start = time.time()\n",
    "        cur_item_sets = []\n",
    "        cur_hash_sets = set()\n",
    "        for i in range(len(frequent_k_item_sets) - 1):\n",
    "            for j in range(i + 1, len(frequent_k_item_sets)):\n",
    "                # joining : find all candidate k item sets\n",
    "                a, b = frequent_k_item_sets[i], frequent_k_item_sets[j]\n",
    "                if a[0][:-1] == b[0][:-1] and a[0][-1] < b[0][-1]:\n",
    "                    candidate_item_set = a[0] + (b[0][-1],)\n",
    "                    # pruning : checking all k - 1 item subsets of candidate\n",
    "                    candidate_subsets = set(\n",
    "                        map(lambda x: tuple(sorted(x)), combinations(set(candidate_item_set), k - 1)))\n",
    "                    if not candidate_subsets - hash_k_sets:\n",
    "                        candidate_sup = (set(candidate_item_set) <= df[\"items\"]).sum()\n",
    "                        if candidate_sup >= min_threshold:\n",
    "                            cur_item_sets.append((candidate_item_set, candidate_sup))\n",
    "                            cur_hash_sets.add(candidate_item_set)\n",
    "        print(f\"Process {k}-item subsets in {time.time() - time_start: .5f} s\")\n",
    "        if len(cur_item_sets) <= 0:\n",
    "            break\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{k}-item frequent item sets\")\n",
    "            print(cur_item_sets)\n",
    "\n",
    "        frequent_sets[k] = cur_item_sets\n",
    "        frequent_k_item_sets = cur_item_sets\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{k}-item hash sets\")\n",
    "            print(cur_hash_sets)\n",
    "\n",
    "        hash_sets[k] = cur_hash_sets\n",
    "        hash_k_sets = cur_hash_sets\n",
    "\n",
    "    if debug:\n",
    "        print(\"Final frequent item sets\")\n",
    "        print(\"=\" * 100)\n",
    "        pprint.pprint(frequent_sets)\n",
    "        print(\"=\" * 100)\n",
    "    return frequent_sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "For dataset1 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01044 s\n",
      "Process 2-item subsets in  0.04714 s\n",
      "Process 3-item subsets in  0.00000 s\n",
      "For dataset2 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.02000 s\n",
      "Process 2-item subsets in  0.04269 s\n",
      "Process 3-item subsets in  0.00000 s\n",
      "For dataset3 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01802 s\n",
      "Process 2-item subsets in  0.05570 s\n",
      "Process 3-item subsets in  0.00000 s\n",
      "For dataset4 : \n",
      "Find frequent item sets by Apriori algorithm\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01800 s\n",
      "Process 2-item subsets in  0.10686 s\n",
      "Process 3-item subsets in  0.02294 s\n",
      "Process 4-item subsets in  0.00795 s\n",
      "Process 5-item subsets in  0.00100 s\n",
      "Process 6-item subsets in  0.00000 s\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "For dataset1 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01333 s\n",
      "Process 2-item subsets in  0.59615 s\n",
      "Process 3-item subsets in  18.24274 s\n",
      "For dataset2 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01000 s\n",
      "Process 2-item subsets in  0.59945 s\n",
      "Process 3-item subsets in  18.53155 s\n",
      "For dataset3 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01656 s\n",
      "Process 2-item subsets in  0.72627 s\n",
      "Process 3-item subsets in  25.79219 s\n",
      "For dataset4 : \n",
      "Find frequent item sets by Brute Force\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Process 1-item subsets in  0.01803 s\n",
      "Process 2-item subsets in  0.61266 s\n",
      "Process 3-item subsets in  18.76463 s\n",
      "Process 4-item subsets in  459.91365 s\n",
      "Stopped\n"
     ]
    }
   ],
   "source": [
    "algos = {\n",
    "    \"Apriori\": apriori_frequent_items,  # apriori\n",
    "     \"Brute Force\": bf_frequent_items,  # brute force\n",
    "}\n",
    "\n",
    "try:\n",
    "    for algo in algos.keys():\n",
    "        print(\"=\" * 100)\n",
    "        for i in range(1,5):\n",
    "            print(\"For dataset\"+str(i)+\" : \")\n",
    "            d = vars()[datasets.loc[i-1,'name']]\n",
    "            items = vars()[(\"items\"+str(i))]\n",
    "            item_counts = vars()[(\"item_counts\"+str(i))]\n",
    "            alg_freq_item_sets = algos[algo](d, items, item_counts, min_sup=0.05, debug=False)\n",
    "        print(\"=\" * 100)\n",
    "except KeyboardInterrupt:\n",
    "    print ('Stopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
